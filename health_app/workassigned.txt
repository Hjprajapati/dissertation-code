FLUTTER INTEGRATION GUIDE (FROM AI ENGINEER TO FLUTTER DEVELOPER)

Hey bro ‚Äî I've completed the entire ML pipeline. Your task now is to integrate the finalized on‚Äëdevice sentiment model into our Flutter app. I'm sharing everything you need below, super clear and actionable.

========================================
1. FILES YOU NEED TO PUT IN THE PROJECT
========================================

Inside the Flutter project, create these folders:

  assets/models/
  assets/tokenizer/

Place the following files exactly here:

  assets/models/student_int8.tflite
  assets/models/label_map.json
  assets/tokenizer/vocab.txt

These 3 files are already exported from the trained model.

========================================
2. UPDATE pubspec.yaml
========================================

Add this under "flutter:"

flutter:
  assets:
    - assets/models/student_int8.tflite
    - assets/models/label_map.json
    - assets/tokenizer/vocab.txt

Then run:
  flutter pub get

========================================
3. ADD DEPENDENCIES
========================================

We will run TFLite on‚Äëdevice using tflite_flutter + ffi.

Add to pubspec.yaml:

dependencies:
  tflite_flutter: ^1.0.0
  tflite_flutter_helper: ^1.0.0

Run:
  flutter pub get

========================================
4. WHAT THE MODEL EXPECTS
========================================

INPUTS (shape: [1, 128]):
  - input_ids      (int32)
  - attention_mask (int32)

OUTPUT:
  - logits (int8 ‚Üí we convert to float)

3-class sentiment:
  ["negative", "neutral", "positive"]

========================================
5. WHAT YOU NEED TO IMPLEMENT
========================================

You only need to complete the Flutter-side pipeline:

1Ô∏è‚É£ Load model from assets
2Ô∏è‚É£ Load vocab.txt (map token ‚Üí id)
3Ô∏è‚É£ Load label_map.json
4Ô∏è‚É£ Write tokenizer function (simple BERT WordPiece rules)
5Ô∏è‚É£ Convert input text ‚Üí token IDs ‚Üí mask
6Ô∏è‚É£ Pad/truncate to length 128
7Ô∏è‚É£ Run interpreter
8Ô∏è‚É£ Convert logits ‚Üí predicted label
9Ô∏è‚É£ Show sentiment output in UI
üîü Add optional latency benchmarking (Stopwatch)

========================================
6. LOADING MODEL (CODE SNIPPET)
========================================

import 'package:tflite_flutter/tflite_flutter.dart' as tfl;
import 'package:flutter/services.dart' show rootBundle;
import 'dart:convert';

late tfl.Interpreter interpreter;
late Map<String, int> vocab;
late List<dynamic> labels;

Future<void> initModel() async {
  interpreter = await tfl.Interpreter.fromAsset(
    'assets/models/student_int8.tflite',
    options: tfl.InterpreterOptions()..threads = 4,
  );

  // load labels
  final labelData =
      await rootBundle.loadString('assets/models/label_map.json');
  labels = jsonDecode(labelData)['labels'];

  // load vocab
  final vocabStr =
      await rootBundle.loadString('assets/tokenizer/vocab.txt');
  vocab = { for (var line in vocabStr.split('
')) 
              if (line.trim().isNotEmpty) 
                line.trim().split(' ')[0]: int.parse(line.trim().split(' ')[1])
          };
}

========================================
7. TOKENIZATION IN DART
========================================

- Convert to lowercase
- Split by spaces
- Look up IDs in vocab
- If missing ‚Üí use vocab['[UNK]']
- Pad/truncate to 128 tokens
- Build attention mask

IMPORTANT TOKEN IDS:
  [CLS], [SEP], [PAD], [UNK] are already in vocab.txt

========================================
8. RUNNING THE MODEL
========================================

List<int> ids = ...;    // length 128
List<int> mask = ...;   // length 128

var output = List.filled(3, 0).reshape([1, 3]);

final stopwatch = Stopwatch()..start();
interpreter.run([ids, mask], output);
stopwatch.stop();

print("Inference time: ${stopwatch.elapsedMilliseconds}ms");

int predIndex = output[0].indexOf(output[0].reduce((a,b)=>a>b?a:b));
String sentiment = labels[predIndex];

========================================
9. UI WORK NEEDED
========================================

- Simple text input
- ‚ÄúAnalyze‚Äù button
- Show:
    - Sentiment label
    - Optional emoji
    - Optional latency value

========================================
10. NOTES FOR ACCURACY & LATENCY
========================================

- Model is fully on-device (TFLite INT8 optimized)
- Expected real-phone latency:
    ‚Ä¢ 20‚Äì60ms on mid/high-end devices
    ‚Ä¢ 80‚Äì120ms on low-end phones
- Meets project requirement: <100ms typical

========================================
11. OPTIONAL (BUT ADD IF POSSIBLE)
========================================

Add a test page:

- Runs 50 inferences
- Logs mean, p50, p90, p99 latency
- Saves results to CSV (for dissertation appendix)

========================================
12. FINAL WORD
========================================

Everything ML-related is DONE.
You only need to:

  ‚Ä¢ wire tokenizer  
  ‚Ä¢ feed IDs to TFLite  
  ‚Ä¢ show output in UI  

If you need any helper functions (Dart tokenizer, input builder, benchmark page), tell me ‚Äî I can generate them.

Let's finish this! üöÄ
